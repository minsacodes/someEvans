#Rename indexes by country
row.names(DataRegGauss)=fromPy$Country
#
# results
gauss1=glm(hypo1,data = DataRegGauss,family = 'gaussian')
gauss2=glm(hypo2,data = DataRegGauss,family = 'gaussian')
summary(gauss1)
summary(gauss2)
anova(gauss1,gauss2,test="Chisq")
library(rsq)
rsq(gauss1,adj=T)
plot(gauss1,1)
plot(gauss1,2)
shapiro.test(gauss1$residuals)
plot(gauss1, 3)
library(lmtest)
bptest(gauss1)
library(car)
vif(gauss1) # lower than 5 is desirable
plot(gauss1,5)
gaussInf=as.data.frame(influence.measures(gauss1)$is.inf)
gaussInf[gaussInf$cook.d,]
library(sjPlot)
plot_models(gauss1,vline.color = "grey")
library(caret)
set.seed(123)
selection = createDataPartition(DataRegGauss$co2_in_millionMT,
p = 0.75,
list = FALSE)
#
trainGauss = DataRegGauss[ selection, ]
#
testGauss  = DataRegGauss[-selection, ]
ctrl = trainControl(method = 'cv',number = 5)
gauss1CV = train(hypo1,
data = trainGauss,
method = 'glm',
trControl = ctrl)
summary(gauss1CV)
predictedVal<-predict(gauss1CV,testGauss)
postResample(obs = testGauss$co2_in_millionMT, pred=predictedVal)
hypoDico1=formula(HDIdico~ demo_FA + co2_in_millionMT)
hypoDico2=formula(HDIdico~ demo_FA + co2_in_millionMT + Continent)
Threshold=median(fromPy$Humandevelopmentindex)
fromPy$HDIdico=fromPy$Humandevelopmentindex>Threshold
fromPy$HDIdico=factor(fromPy$HDIdico,
levels = c(F,T),
labels = c(0,1))
colsNeededDico=c('HDIdico','demo_FA','co2_in_millionMT','Continent')
str(fromPy[,colsNeededDico])
DataRegLogis=fromPy[,colsNeededDico]
#Rename indexes by country
row.names(DataRegLogis)=fromPy$Country
Logi1=glm(hypoDico1,data = DataRegLogis,family = "binomial")
Logi2=glm(hypoDico2,data = DataRegLogis,family = "binomial")
summary(Logi1)
summary(Logi2)
lrtest(Logi1,Logi2)
DataRegLogis2=DataRegLogis
DataRegLogis2$demoTEST=DataRegLogis$demo_FA*log(DataRegLogis$demo_FA)
DataRegLogis2$co2TEST=DataRegLogis$co2_in_millionMT*log(DataRegLogis$co2_in_millionMT)
hypoDicoTest=formula(HDIdico~ demo_FA + co2_in_millionMT + Continent + demoTEST + co2TEST)
summary(glm(hypoDicoTest,data=DataRegLogis2,family = binomial))
vif(Logi2)
plot(Logi2,5)
library(margins)
(modelChosen = margins(Logi2))
(margins=summary(modelChosen))
base= ggplot(margins,aes(x=factor, y=AME)) + geom_point()
plot2 = base + theme(axis.text.x = element_text(angle = 80,
size = 6,
hjust = 1))
plot2
plot2 +  geom_errorbar(aes(ymin=lower, ymax=upper))
set.seed(123)
selection = createDataPartition(DataRegLogis$HDIdico,
p = 0.75,
list = FALSE)
trainLogi = DataRegLogis[selection, ]
testLogi  = DataRegLogis[-selection, ]
ctrl = trainControl(method = 'cv',number = 5)
Logis2CV = train(hypoDico2,
data = trainLogi,
method = 'glm',
family="binomial",
trControl = ctrl)
summary(Logis2CV)
predictions = predict(Logis2CV,
newdata=testLogi,
type='raw')
confusionMatrix(data=predictions,
reference=testLogi$HDIdico,
positive = "1")
link='https://github.com/UWDataScience2020/data/raw/master/hdidemocia.RDS'
# a RDS file from the web needs:
myFile=url(link)
# reading in data:
fromPy=readRDS(file = myFile)
# reset indexes to R format:
row.names(fromPy)=NULL
str(fromPy,width = 70,strict.width='cut')
library(matlab)
top=10*as.vector(ones(1,5))
bottom=as.vector(zeros(1,5))
# those become two rows of a data frame
limitCases=as.data.frame(rbind(bottom,top))
limitCases
subDemo=fromPy[,c(8:12)]
# FIRST, we need both DFs share same column names
names(limitCases)=names(subDemo)
# appending:
subDemo=rbind(subDemo,limitCases)
names(subDemo)
library(lavaan)
model='
dem=~Electoralprocessandpluralism + Functioningofgovernment + Politicalparticipation + Politicalculture + Civilliberties
'
fit<-cfa(model, data = subDemo,std.lv=TRUE)
indexCFA=lavPredict(fit)
library(magrittr)
indexCFA%>%head(10)
library(scales)
indexCFANorm=rescale(as.vector(indexCFA), to = c(0, 10))
tail(indexCFANorm)
fromPy$demo_FA=head(indexCFANorm,-2)
library(ggplot2)
base=ggplot(data=fromPy,
aes(x=demo_FA))
base+geom_histogram()
base=ggplot(data=fromPy,
aes(x=demo_FA,y=Score))
base+geom_point()
evalCFA1=parameterEstimates(fit, standardized =TRUE)
evalCFA1[evalCFA1$op=="=~",c('rhs','std.all','pvalue')]
evalCFA2=as.list(fitMeasures(fit))
evalCFA2[c("chisq", "df", "pvalue")]
evalCFA2$tli # > 0.90
evalCFA2[c( 'rmsea.ci.lower','rmsea','rmsea.ci.upper')]
library(semPlot)
semPaths(fit, what='std', nCharNodes=10, sizeMan=8,
edge.label.cex=1.5, fade=T,residuals = F)
# hypotheses:
hypo1=formula(co2_in_millionMT~ demo_FA + Humandevelopmentindex)
hypo2=formula(co2_in_millionMT~ demo_FA + Humandevelopmentindex + Continent)
fromPy$co2_in_millionMT=fromPy$co2_in_MT/10^6
colsNeeded=c('co2_in_millionMT', 'demo_FA','Humandevelopmentindex','Continent')
str(fromPy[,colsNeeded])
DataRegGauss=fromPy[,colsNeeded]
#Rename indexes by country
row.names(DataRegGauss)=fromPy$Country
#
# results
gauss1=glm(hypo1,data = DataRegGauss,family = 'gaussian')
gauss2=glm(hypo2,data = DataRegGauss,family = 'gaussian')
summary(gauss1)
summary(gauss2)
anova(gauss1,gauss2,test="Chisq")
library(rsq)
rsq(gauss1,adj=T)
plot(gauss1,1)
plot(gauss1,2)
shapiro.test(gauss1$residuals)
plot(gauss1, 3)
library(lmtest)
bptest(gauss1)
library(car)
vif(gauss1) # lower than 5 is desirable
plot(gauss1,5)
gaussInf=as.data.frame(influence.measures(gauss1)$is.inf)
gaussInf[gaussInf$cook.d,]
library(sjPlot)
plot_models(gauss1,vline.color = "grey")
library(caret)
set.seed(123)
selection = createDataPartition(DataRegGauss$co2_in_millionMT,
p = 0.75,
list = FALSE)
#
trainGauss = DataRegGauss[ selection, ]
#
testGauss  = DataRegGauss[-selection, ]
ctrl = trainControl(method = 'cv',number = 5)
gauss1CV = train(hypo1,
data = trainGauss,
method = 'glm',
trControl = ctrl)
summary(gauss1CV)
predictedVal<-predict(gauss1CV,testGauss)
postResample(obs = testGauss$co2_in_millionMT, pred=predictedVal)
hypoDico1=formula(HDIdico~ demo_FA + co2_in_millionMT)
hypoDico2=formula(HDIdico~ demo_FA + co2_in_millionMT + Continent)
Threshold=median(fromPy$Humandevelopmentindex)
fromPy$HDIdico=fromPy$Humandevelopmentindex>Threshold
fromPy$HDIdico=factor(fromPy$HDIdico,
levels = c(F,T),
labels = c(0,1))
colsNeededDico=c('HDIdico','demo_FA','co2_in_millionMT','Continent')
str(fromPy[,colsNeededDico])
DataRegLogis=fromPy[,colsNeededDico]
#Rename indexes by country
row.names(DataRegLogis)=fromPy$Country
Logi1=glm(hypoDico1,data = DataRegLogis,family = "binomial")
Logi2=glm(hypoDico2,data = DataRegLogis,family = "binomial")
summary(Logi1)
summary(Logi2)
lrtest(Logi1,Logi2)
DataRegLogis2=DataRegLogis
DataRegLogis2$demoTEST=DataRegLogis$demo_FA*log(DataRegLogis$demo_FA)
DataRegLogis2$co2TEST=DataRegLogis$co2_in_millionMT*log(DataRegLogis$co2_in_millionMT)
hypoDicoTest=formula(HDIdico~ demo_FA + co2_in_millionMT + Continent + demoTEST + co2TEST)
summary(glm(hypoDicoTest,data=DataRegLogis2,family = binomial))
vif(Logi2)
plot(Logi2,5)
library(margins)
(modelChosen = margins(Logi2))
(margins=summary(modelChosen))
base= ggplot(margins,aes(x=factor, y=AME)) + geom_point()
plot2 = base + theme(axis.text.x = element_text(angle = 80,
size = 6,
hjust = 1))
plot2
plot2 +  geom_errorbar(aes(ymin=lower, ymax=upper))
set.seed(123)
selection = createDataPartition(DataRegLogis$HDIdico,
p = 0.75,
list = FALSE)
trainLogi = DataRegLogis[selection, ]
testLogi  = DataRegLogis[-selection, ]
set.seed(123)
ctrl = trainControl(method = 'cv',number = 5)
Logis2CV = train(hypoDico2,
data = trainLogi,
method = 'glm',
family="binomial",
trControl = ctrl)
summary(Logis2CV)
predictions = predict(Logis2CV,
newdata=testLogi,
type='raw')
confusionMatrix(data=predictions,
reference=testLogi$HDIdico,
positive = "1")
confusionMatrix(data=predictions,
reference=testLogi$HDIdico,
positive = "1")
link='https://github.com/UWDataScience2020/data/raw/master/hdidemocia.RDS'
# a RDS file from the web needs:
myFile=url(link)
# reading in data:
fromPy=readRDS(file = myFile)
# reset indexes to R format:
row.names(fromPy)=NULL
str(fromPy,width = 70,strict.width='cut')
library(matlab)
top=10*as.vector(ones(1,5))
bottom=as.vector(zeros(1,5))
# those become two rows of a data frame
limitCases=as.data.frame(rbind(bottom,top))
limitCases
subDemo=fromPy[,c(8:12)]
# FIRST, we need both DFs share same column names
names(limitCases)=names(subDemo)
# appending:
subDemo=rbind(subDemo,limitCases)
names(subDemo)
library(lavaan)
model='
dem=~Electoralprocessandpluralism + Functioningofgovernment + Politicalparticipation + Politicalculture + Civilliberties
'
fit<-cfa(model, data = subDemo,std.lv=TRUE)
indexCFA=lavPredict(fit)
library(magrittr)
indexCFA%>%head(10)
library(scales)
indexCFANorm=rescale(as.vector(indexCFA), to = c(0, 10))
tail(indexCFANorm)
fromPy$demo_FA=head(indexCFANorm,-2)
library(ggplot2)
base=ggplot(data=fromPy,
aes(x=demo_FA))
base+geom_histogram()
base=ggplot(data=fromPy,
aes(x=demo_FA,y=Score))
base+geom_point()
evalCFA1=parameterEstimates(fit, standardized =TRUE)
evalCFA1[evalCFA1$op=="=~",c('rhs','std.all','pvalue')]
evalCFA2=as.list(fitMeasures(fit))
evalCFA2[c("chisq", "df", "pvalue")]
evalCFA2$tli # > 0.90
evalCFA2[c( 'rmsea.ci.lower','rmsea','rmsea.ci.upper')]
library(semPlot)
semPaths(fit, what='std', nCharNodes=10, sizeMan=8,
edge.label.cex=1.5, fade=T,residuals = F)
# hypotheses:
hypo1=formula(co2_in_millionMT~ demo_FA + Humandevelopmentindex)
hypo2=formula(co2_in_millionMT~ demo_FA + Humandevelopmentindex + Continent)
fromPy$co2_in_millionMT=fromPy$co2_in_MT/10^6
colsNeeded=c('co2_in_millionMT', 'demo_FA','Humandevelopmentindex','Continent')
str(fromPy[,colsNeeded])
DataRegGauss=fromPy[,colsNeeded]
#Rename indexes by country
row.names(DataRegGauss)=fromPy$Country
#
# results
gauss1=glm(hypo1,data = DataRegGauss,family = 'gaussian')
gauss2=glm(hypo2,data = DataRegGauss,family = 'gaussian')
summary(gauss1)
summary(gauss2)
anova(gauss1,gauss2,test="Chisq")
library(rsq)
rsq(gauss1,adj=T)
plot(gauss1,1)
plot(gauss1,2)
shapiro.test(gauss1$residuals)
plot(gauss1, 3)
library(lmtest)
bptest(gauss1)
library(car)
vif(gauss1) # lower than 5 is desirable
plot(gauss1,5)
gaussInf=as.data.frame(influence.measures(gauss1)$is.inf)
gaussInf[gaussInf$cook.d,]
library(sjPlot)
plot_models(gauss1,vline.color = "grey")
library(caret)
set.seed(123)
selection = createDataPartition(DataRegGauss$co2_in_millionMT,
p = 0.75,
list = FALSE)
#
trainGauss = DataRegGauss[ selection, ]
#
testGauss  = DataRegGauss[-selection, ]
ctrl = trainControl(method = 'cv',number = 5)
gauss1CV = train(hypo1,
data = trainGauss,
method = 'glm',
trControl = ctrl)
summary(gauss1CV)
predictedVal<-predict(gauss1CV,testGauss)
postResample(obs = testGauss$co2_in_millionMT, pred=predictedVal)
hypoDico1=formula(HDIdico~ demo_FA + co2_in_millionMT)
hypoDico2=formula(HDIdico~ demo_FA + co2_in_millionMT + Continent)
Threshold=median(fromPy$Humandevelopmentindex)
fromPy$HDIdico=fromPy$Humandevelopmentindex>Threshold
fromPy$HDIdico=factor(fromPy$HDIdico,
levels = c(F,T),
labels = c(0,1))
colsNeededDico=c('HDIdico','demo_FA','co2_in_millionMT','Continent')
str(fromPy[,colsNeededDico])
DataRegLogis=fromPy[,colsNeededDico]
#Rename indexes by country
row.names(DataRegLogis)=fromPy$Country
Logi1=glm(hypoDico1,data = DataRegLogis,family = "binomial")
Logi2=glm(hypoDico2,data = DataRegLogis,family = "binomial")
summary(Logi1)
summary(Logi2)
lrtest(Logi1,Logi2)
DataRegLogis2=DataRegLogis
DataRegLogis2$demoTEST=DataRegLogis$demo_FA*log(DataRegLogis$demo_FA)
DataRegLogis2$co2TEST=DataRegLogis$co2_in_millionMT*log(DataRegLogis$co2_in_millionMT)
hypoDicoTest=formula(HDIdico~ demo_FA + co2_in_millionMT + Continent + demoTEST + co2TEST)
summary(glm(hypoDicoTest,data=DataRegLogis2,family = binomial))
vif(Logi2)
plot(Logi2,5)
library(margins)
(modelChosen = margins(Logi2))
(margins=summary(modelChosen))
base= ggplot(margins,aes(x=factor, y=AME)) + geom_point()
plot2 = base + theme(axis.text.x = element_text(angle = 80,
size = 6,
hjust = 1))
plot2
plot2 +  geom_errorbar(aes(ymin=lower, ymax=upper))
set.seed(123)
selection = createDataPartition(DataRegLogis$HDIdico,
p = 0.75,
list = FALSE)
trainLogi = DataRegLogis[selection, ]
testLogi  = DataRegLogis[-selection, ]
set.seed(123)
ctrl = trainControl(method = 'cv',number = 5)
Logis2CV = train(hypoDico2,
data = trainLogi,
method = 'glm',
family="binomial",
trControl = ctrl)
summary(Logis2CV)
predictions = predict(Logis2CV,
newdata=testLogi,
type='raw')
confusionMatrix(data=predictions,
reference=testLogi$HDIdico,
positive = "1")
?ggRadar
library(ggiraph)
library(ggiraphExtra)
?ggRadar
ggRadar
library(openxlsx)
link="https://github.com/EvansDataScience/data/raw/master/safeCitiesIndexAll.xlsx"
safe=read.xlsx(link)
names(safe)
# all the questions with this: "H_In_"
grep("H_In_", colnames(safe) ) # ^ means starts with
# the 'head' of only those:
healthIN=grep("H_In_", colnames(safe) )
head(safe[,c(1,healthIN)])
pairs(safe[,c(healthIN)])
library(ggplot2)
library(GGally) # may need to install
ggcorr(safe[,-1], # all but the first column
hjust = 0.9,# distance to plot (diagonal)
size=1, # font size
layout.exp=4, # width so that variable names are shown
low = 'red',high = 'blue') # color scale
base= ggcorr(safe[,-1],size=1,layout.exp=4,hjust=0.9,
nbreaks = 3, # 3 intervals
palette = "PuOr")
base + guides(fill=guide_legend("some title")) # if you need a title for legend
library(reshape)
safeA=melt(safe,
id.vars = 'city') # the unit of analysis
head(safeA)
base = ggplot(data = safeA, aes(x = variable,
y =city))
heat1= base +  geom_tile(aes(fill = value))
heat1
#inverse color -1
heat2 = heat1 + scale_fill_distiller(palette = "RdYlGn",direction = 1)
heat2
heat2 + theme(axis.text.x = element_text(angle = 90,
hjust = 1,
size = 4),
axis.text.y = element_text(size = 4))
# change in REORDER
base= ggplot(data = safeA, aes(x = reorder(variable,
value, median, order=TRUE),
y =reorder(city,
value, median, order=TRUE)))
# THIS IS THE SAME
base + geom_tile(aes(fill = value)) +
scale_fill_distiller(palette = "RdYlGn",direction = 1) +
theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 4),
axis.text.y = element_text(size = 4))
library(openxlsx)
link2="https://github.com/EvansDataScience/data/raw/master/safeCitiesIndex.xlsx"
safe2=read.xlsx(link2)
head(safe2)
safe2A=melt(safe2,id.vars = 'city')
head(safe2A)
base  = ggplot(safe2A, aes(x = variable, y = value, group = city))
plot1 = base + geom_polygon(fill = 'gray',col='orange') + coord_polar()
plot2 = plot1 + facet_wrap(~city,# one plot per city
ncol = 10) # ten plot per row
plot2
plot2 = plot1 + facet_wrap(~reorder(city,value, median, order=TRUE),ncol = 7)
plot3 = plot2 + theme(axis.text.x = element_text(size = 8))
plot3
plot3 = plot2 + theme(axis.text.x = element_text(size = 8),
legend.position="none",
strip.text = element_text(size = 20)) #here!!!
plot3
### arguments
brdBkgnGrid=element_rect(fill = "white",colour = "red",
size = 3,linetype = "dashed")
lineGrid=element_line(size = 3,linetype = 'solid',colour = "blue")
### more customization
plot3+ theme(panel.background = brdBkgnGrid,
panel.grid.major = lineGrid)
# copy data
safe2x=safe2
head(safe2x)
# get minimun value by row
safe2x$min=apply(safe2x[,c(2:5)],1,min)
# turn this min values into a ranking
safe2x$min=rank(safe2x$min,ties.method ='first' )
# order city by ranking
cityRk=as.factor(safe2x[order(safe2x$min),]$city)
# turn city into ordered factor
safe2x$city=factor(safe2x$city,
levels= cityRk,
labels = cityRk,
ordered = T)
# delete column with ranks
safe2x$min=NULL
head(safe2x)
str(safe2x)
library(ggiraph)
library(ggiraphExtra)
base = ggRadar(safe2x,aes(group='city'),legend.position="none") +geom_point(color='black')
plot1 = base + facet_wrap(~city,ncol = 10)
plot1 + geom_polygon(fill = 'white',col='orange')
library(ggiraph)
library(ggiraphExtra)
base = ggRadar(safe2x,aes(group='city'),legend.position="none")
plot1 = base + facet_wrap(~city,ncol = 10)
plot1 + geom_polygon(fill = 'white',col='orange') +geom_point(color='black')
library(ggiraph)
library(ggiraphExtra)
base = ggRadar(safe2x,aes(group='city'),legend.position="none")
plot1 = base + facet_wrap(~city,ncol = 10)
plot1 + geom_polygon(fill = 'white',col='orange') +geom_point(color='red')
some=c("Manila","Lima", "Washington DC","Tokyo")
subSafe=safe2x[safe2x$city %in% some,]
base = ggRadar(subSafe,aes(group='city'),
alpha = 0,legend.position="top")
base #+  theme(legend.title=element_blank())
plot3
plot3 + theme_classic()
ggPair(iris,aes(color=Species),horizontal=TRUE,interactive=TRUE)
?ggPair
