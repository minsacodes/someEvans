<br> 
<center><img src="http://i.imgur.com/sSaOozN.png" width="500"></center>


## Course: VISUAL ANALYTICS FOR POLICY AND MANAGEMENT

### Prof. José Manuel Magallanes, PhD 
* Visiting Professor of Computational Policy at Evans School of Public Policy and Governance, and eScience Institute Senior Data Science Fellow, University of Washington.
* Professor of Government and Political Methodology, Pontificia Universidad Católica del Perú. 


_____
<a id='TOC'></a>

# Session 3: Tabular data: Univariate Numerical

_____

1. [Counting](#part1)

2. [Measuring](#part2)


_____



Let's load the data we used for the last session:

```{r getData, eval=FALSE}
link='https://github.com/EvansDataScience/data/raw/master/eduwa.rda'

#getting the data TABLE from the file in the cloud:
load(file=url(link))
```

<a id='part1'></a>

## Data from Counting

Counting expresses numerical values. They could be represented with bar plots if their frequency table had few different values, but that is not the case. For example, the variable _Reduced.Lunch_ informs how many kids there are in each school that have that lunch for a reduced price. We have more than 2000 schools, so it is possible to have that many different values. This is how many different values we have:

```{r unique, eval=FALSE}
# how many unique values
length(unique(eduwa$Reduced.Lunch))
```

There are too many different values. Then, the bar plot is not a good idea (and neither a frequency table), as the bar plot produces a bar for each unique value in the data, counting how many times this value appeared. Now, we have many values, so we need to organize the data into _intervals_. However, when you have a numerical variable you should keep in mind:

* What is the representative value? Generally the mean, and median in the presence of outliers. 

* Does the shape of the distribution differs from a normal distribution? 

    - How well is the representative value? You need some measure of dispersion. For the mean you have the **standard deviation**, and for the median the **median absolute deviation**. You can also compute a measure of kurtosis.
    - If there is asymmetry, is it big enough to show outliers? The boxplot will help you identify outliers, but you can compute a measure of asymetry.

You can get several info from this command:

```{r summary, eval=FALSE}
summary(eduwa$Reduced.Lunch)
```

The **summary** command can be suplemented with:
```{r, eval=FALSE}
# standard deviation:
sd(eduwa$Reduced.Lunch,na.rm = T)
```

```{r, eval=FALSE}
# median absolute deviation:
mad(eduwa$Reduced.Lunch,na.rm = T)
```

```{r, eval=FALSE}
# asymmetry
library(DescTools)
Skew(eduwa$Reduced.Lunch,
     na.rm = T,
     conf.level = 0.95,
     ci.type = "bca",
     R=2500)

```

```{r, eval=FALSE}
# shape
#library(DescTools)
Kurt(eduwa$Reduced.Lunch,
     na.rm = T,conf.level = 0.95,
     ci.type = "bca",R=2500)
```


With the values computed, can you guess how a histogram or a boxplot would look?

The **histogram** is the basic plot, you can use the element **geom_histogram()** :

```{r GGLikeBase,eval=FALSE}
#ggplot
WIDTH=10
library(ggplot2)
base= ggplot(eduwa,aes(x = Reduced.Lunch))  
h1= base + geom_histogram(binwidth = WIDTH) 
h1 
```

The histogram look like a bar plot. In both cases the height of the bars represent counts, but the bars in the histogram are consecutive while the bases of the bars are numeric intervals (**binwidth** informs the length of the intervals). The height of the bars could represent percentages if you ask for it:


```{r, eval=FALSE}
h1p= base + geom_histogram(binwidth = WIDTH,aes(y=stat(density*WIDTH))) 
h1p
```

I am pretty sure you prefer to see percent values:

```{r, eval=FALSE}
library(scales)
h1p=h1p+scale_y_continuous(labels = scales::percent_format())
h1p
```

It is better to have labels for better reading the height:

```{r, eval=FALSE}
h1p=h1p+scale_y_continuous(labels = scales::percent_format(),breaks = c(0.1,0.2,0.25,0.3),limits = c(0,0.3))
h1p
```

One of the central measures could be used as a reference:
```{r, eval=FALSE}
MEAN=summary(eduwa$Reduced.Lunch)[4]
h1+ geom_vline(xintercept = MEAN)
```


What else would you do here to make a good plot?


The boxplot can also be used in these data:

```{r, eval=FALSE}
base= ggplot(eduwa,aes(y = Reduced.Lunch))  
b1= base + geom_boxplot() 
b1 +coord_flip()
```

The statistical summary includes some the values shown in the boxplot:

```{r, eval=FALSE}
summary(eduwa$Reduced.Lunch)
```

I can keep these values without the count of NAs:
```{r, eval=FALSE}
(statVals=summary(eduwa$Reduced.Lunch,digits = 3)[1:6])
```


Let me put some of those values in the boxplot y-axis:

```{r, eval=FALSE}
library(magrittr)
statVals=statVals%>%as.vector() 

base= ggplot(eduwa,aes(y = Reduced.Lunch))  
b1= base + geom_boxplot() 
b1=b1 +coord_flip()
b1=b1+ scale_y_continuous(breaks = statVals)
b1
```


This boxplot shows outliers, that means there is an upper threshold. I can get that value using the interquartile range, which is:

```{r, eval=FALSE}
# difference between q3 and q1:
(theIQR=IQR(eduwa$Reduced.Lunch,na.rm = T))
```

Then, you simply add to the top and bottom quartile the IQR multiply by a factor (typically 1.5) to get the upper threshold:
```{r, eval=FALSE}
(upperT=summary(eduwa$Reduced.Lunch)[[5]] + theIQR*1.5)
```

Knowing the upper threshold, I can compute the amount of upper outliers:
```{r, eval=FALSE}
sum(eduwa$Reduced.Lunch>upperT,na.rm = T)
```

I can annotate my boxplot with ths value:

```{r, eval=FALSE}
annotation=paste0('Threshold:',upperT)
b1 = b1 + geom_hline(yintercept = upperT,
                     color='grey8',
                     linetype="dotted",
                     size=2) 
b1=b1 + annotate(geom = 'text',
              label=annotation,
              y = upperT+5,
              x=0.2,
              angle=90)
b1
```


You can not see clearly the horizontal values, and the vertical values are confusing, then:

```{r, eval=FALSE}
b1x=b1+ theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          axis.title.y = element_blank())
b1x + theme(axis.text.x = element_text(angle = 90,size = 8,vjust = 0.5))
```

In general, measurements and counts are prone to have outliers. It is not common to speak about outliers in ordinal data since they have few levels. From what I just said, the subjective side of finding outliers lies in the decision of **what "normal" means**. In the case of the boxplot, the decision has been to accept as normal the values that have a *prudent distance* from the first or last quartile. The distance chosen was 1.5 times the difference between the quartiles (a.k.a. Interquartle Range or **IQR**). Then, if a outlier is found, the whisker ends in a position different than the actual minimum or maximal value of the data.

[Go to table of contents.](#TOC)

<a id='part2'></a>

### Measurement

A simplistic idea of measurement tells you the times a particular unit is present in the unit of analysis; which allows for the presence of decimal places. There are variables that can have negative values.

Let's analyze the variable _Student.Teacher.Ratio_:

```{r summaryMeans, eval=FALSE}
summary(eduwa$Student.Teacher.Ratio)
```

Notice that the maximum value is very far from the mean and the median, this announces the presence of outliers:

```{r, eval=FALSE}
base=ggplot(eduwa) + theme_classic()
box2=base + geom_boxplot(aes(y=Student.Teacher.Ratio))
box2 + coord_flip()
```

Outliers may tell you that there are different populations in these data. Let me split the data using the thresholds. This time, I will get the thresholds using \emph{ggplot_build}:

```{r boththresolds, eval=FALSE}
lowerT=ggplot_build(box2)$data[[1]]$ymin
upperT=ggplot_build(box2)$data[[1]]$ymax
```

Now, let me keep the data without outliers:
```{r, eval=FALSE}
theVAR=eduwa$Student.Teacher.Ratio
normals=eduwa[which(theVAR >=lowerT & theVAR <= upperT),]
```

Let's make the histogram with these reduced data:

```{r, eval=FALSE}

WIDTH=0.6
baseN=ggplot(normals,
             aes(x=Student.Teacher.Ratio)) +
      theme_minimal() 
histN=baseN+geom_histogram(binwidth=WIDTH)
histN
```

This last subset produces a bell-shaped histogram. Sometimes you can compare it to the gaussian or normal curva that exists with the mean and standard deviation of your data:

```{r, eval=FALSE}
# paramaters for ideal normal curve
N=nrow(normals)
MEAN=mean(normals$Student.Teacher.Ratio,
          na.rm = TRUE)
SD=sd(normals$Student.Teacher.Ratio,
      na.rm = TRUE)
# my function to create a normal curve
idealNormal=function(aesX)
            {dnorm(aesX,
                   mean = MEAN,
                   sd = SD) * N * WIDTH}
```

Let me use the previous data to overlay an ideal normal curve on top the real data:
```{r, eval=FALSE}
# real distribution
hi2=baseN+ geom_histogram(binwidth = WIDTH,
                          size = 0.1) 
# normal distribution
hi2=hi2+stat_function(fun = idealNormal,
    color = "red", size = 1)

hi2
```


You do not need to overlay a normal curve in your histograms, unless the audience understands the properties it has. For instance, let me compute the values that are far from the mean by two standard deviations: 

```{r, eval=FALSE}
(thresholds=c(MEAN - 2*SD, MEAN + 2*SD))

```

This means that the probability of observing values below or above those values is less than 5%. The data has some of those values:
```{r, eval=FALSE}
summary(normals$Student.Teacher.Ratio)
```


I will use those thresholds to inform the areas where the least probable values reside:

```{r, eval=FALSE}
hi2=hi2 + geom_vline(xintercept = thresholds,color='blue')
hi2
```


You can have a legend for these annotations:

```{r, eval=FALSE}

hi2=baseN+ geom_histogram(binwidth = WIDTH,
                   size = 0.1) 
hi2=hi2+stat_function(fun = idealNormal,
                      aes(color = "Normal"))

hi2=hi2 + geom_vline(aes(xintercept =thresholds[1],
                        color='TwoSigma1'),
                     show.legend = F)
hi2=hi2 + geom_vline(aes(xintercept =thresholds[2],
                        color='TwoSigma2'),
                     show.legend = F)
hi2=hi2 + scale_color_manual(name = "References",
                        values = c(Normal = "red",TwoSigma1 = "grey",TwoSigma2 = "black"),
                        labels=c("Normal Curve","-2sd","+2sd"))
hi2 
```

Another visual for the statistician's eye can be the **cummulative distribution**. A simple way of doing it would be like this:

```{r, eval=FALSE}
histN+ stat_bin(aes(y=cumsum(..count..)),geom="line",bins=28,col='red') 
```

I know there are 28 bins by counting the bars in the histogram. But, you can recover that with the function *ggplot_build* again. Let's see what we have:

```{r, eval=FALSE}
histInfo=ggplot_build(histN)$data[[1]]
head(histInfo)
```

Then:
```{r, eval=FALSE}
nrow(histInfo)
```

You see that the cumulative reaches almost 2000. I can confirm that here:

```{r, eval=FALSE}
cumsum(histInfo$count)
```

I can combine both plot using **TWO VERTICAL AXES**. But I need some extra work:

1. Get the max value of Y axis:
```{r, eval=FALSE}
TopValueY <- max(histInfo$y)
```

2. Use **stat_ecdf()** function on top. You need to multiple the values by the previously computed values (TopValueY):

```{r, eval=FALSE}
histN2=histN +
  stat_ecdf(aes(y=..y..*TopValueY)) 
```

3. Add the secondary axis:

```{r, eval=FALSE}
histN2=histN2 +
  scale_y_continuous(name = "Count", 
                     sec.axis = sec_axis(trans = ~./TopValueY,name = "ECDF",breaks = c(0,.50,.80),
                                         labels = scales::percent_format()))
histN2
```

You can try intersecting lines:

```{r, eval=FALSE}
MEDIAN=median(normals$Student.Teacher.Ratio,
          na.rm = TRUE)
histN3=histN2+geom_hline(yintercept = TopValueY*0.5)+geom_vline(xintercept = MEDIAN)

histN3
```


If you prefer, you can use the basic statistics in you horizontal axis:


```{r, eval=FALSE}
STATS=summary(normals$Student.Teacher.Ratio)%>% as.vector() %>%round(.,1)
histN3 + scale_x_continuous(breaks =STATS)

```


Exercise:

For the final project, you should choos one of the plots shown here. Adapt  one of the plots in this session, complete it with the missing elements, and make any improvement you consider important.


_____
[Go to table of contents.](#TOC)
